\section{Related Work}

My research is based on prior work that explores making recommendations to developers and technical approaches to increasing software engineering action adoption.

\subsection{Developer Recommendations} 

Prior work has investigated different methods for making effective recommendations to software developers. One such method is in-person interactions between with colleagues, which research suggests is the most effective way to make suggestions to software engineers. Murphy-Hill explored seven methods software engineers learn about new development tools and found that \textit{peer interactions} were the most effective~\cite{Murphy-Hill2015HowDoUsers}. Additionally, Cockburn and Williams suggest that collaboration occurring pair programming is useful for saving time and money in addition to  improving developer work satisfaction, design quality, code reviews, problem solving abilities, learning, team building, communication, and project management within an  organization~\cite{WilliamsPairProgramming}. Likewise, Maaleej also analyzed peer debriefings, or discussions between developers, and found that these peer interactions are effective for improving code comprehension~\cite{Maalej2014Comprehension}. Furthermore, Bacchelli and colleagues suggest that learning is an important benefit of code reviews between programmers working together on a software development team~\cite{bacchelli2013codereview}. 

Researchers have also explored the impact of passive help systems on developer learning. These static systems include Stack Overflow~\cite{barua2014developers}, Twitter~\cite{singer2014twitter}, Hacker News~\cite{barik2015heart}, GitHub~\cite{dabbish2012social}, software documentation~\cite{Forward2002Documentation}, and social media in general~\cite{begel2010social}. Furthermore, prior work has proposed and evaluated methods to improve developer recommendations and help solve the software engineering adoption problem. Examples of these methods include idea gardening~\cite{CaoIdeaGarden}, automated pull requests~\cite{SamUgrade}, continuous screencasting~\cite{Murphy-HillScreencastingDiscovery}, live-coding~\cite{blackwell2014collaboration}, crowdsourcing ~\cite{gordon2015codepourri}, explorative and exploitative searching~\cite{karim2018learn}, logging activities~\cite{ToolBox}, organization-wide learning~\cite{OWL}, shared knowledge bases~\cite{Spyglass}, and gamification~\cite{barik2016game}. Additionally, software engineering researchers have also suggested using theories from other fields to improve developer recommendations. For example, Fleming and colleagues examined applying \textit{information foraging theory}, the study of how humans search for information, to software engineering and how programmers seek information ~\cite{fleming2013information}. Furthermore, Singer explored integrating concepts from \textit{diffusion of innovations}, a sociology theory for explaining how knowledge and ideas spread, to increase tool adoption among software developers~\cite{Diffusion}. To our knowledge, our work is the first research to integrate nudge theory into developer recommendations to improve the decision-making and behavior of software engineers.

\subsection{Recommendation Systems for Software Engineering} 

Software engineering researchers and toolsmithshave developed and evaluated many active help systems to assist programmers. Robillard and colleagues define and provide examples of RSSEs in the context of software development~\cite{RSSE}. Prior work has introduced a variety of tools to make recommendations and help developers complete a wide range of programming tasks. For example, Spyglass improves code navigation~\cite{Spyglass}, ToolBox recommends Unix commands~\cite{ToolBox}, Tricorder suggests static analysis bugs to fix~\cite{Tricorder}, Coronado recommends queries to improve code searching~\cite{Coronado}, Dhruv suggests developers and artifacts to resolve bug reports~\cite{Dhruv}, and many more. Besides these active help systems, research has also explored the use of software robots, or bots, to automatically make recommendations to developers. For example, David-DM\footnote{\url{https://david-dm.org/}} and Greenkeeper\footnote{\url{https://greenkeeper.io/}} are bots designed to recommend dependency updates for developers~\cite{sam2017autopullrequests}. Beschastnikh and colleagues also implemented analysis bots to increase the adoption of software engineering research in industry~\cite{beschastnikh2017accelerating}.

In addition to developing automated recommender systems, research has also explored ways to improve the overall effectiveness of these systems. Fogg also outlines design principles for creating and designing persuasive technologies to encourage users to adopt target behaviors~\cite{Fogg2009Persuasive}. Furthermore, McNee and colleagues argue that the accuracy of recommender systems is not sufficient for increasing adoption and suggest developers of recommender systems must implement \textit{user-centric} recommendations focused on user experiences and expectations~\cite{McNee2006Accuracy}. Similarly, Konstan and colleagues posit that evaluating user experiences metrics is more important for automated recommender systems than optimizing recommendation algorithms~\cite{konstan2012recommender}. For RSSEs, Murphy and Murphy-Hill explored the concept of trust in recommender systems for software development and found that trust was more important than precision for software engineers~\cite{murphy2010trust}. Our work also seeks to improve the effectiveness of recommender bots by focusing on integrating concepts from nudge theory in recommendations to improve developer decision-making and behavior.

\subsection{Nudge Theory in Software}

To our knowledge, this is the first work exploring the impact of nudge theory on software developers. However, prior work has examined using digital nudges to influence the behavior of software users. For example, Weinmann and colleagues argue that user interface design can impact user behavior and decision-making in digital choice environments~\cite{weinmann2016digitalnudging}. Acquisti and colleagues explored using digital nudges to improve user privacy and security decisions online~\cite{acquisti2017nudges}. Likewise, Huang and colleagues found that digitally nudging social media users impacted social sharing behavior~\cite{huang2018digital}. Additionally, Gupta and colleagues studied using digital nudge interventions to improve distributed team performance on the Test of Collective Intelligence, an online evaluation to measure the ability of team to collaborate and complete a series of tasks~\cite{gupta2019digitally}. While these studies show that digital nudges are effective for impacting the behavior of software users, we aim to discover if the nudge theory framework can also improve behavior and decision-making of software developers.